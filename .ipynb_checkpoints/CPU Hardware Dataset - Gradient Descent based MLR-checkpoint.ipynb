{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## DATA IO ##\n",
    "#############\n",
    "\n",
    "def get_data(filepath):\n",
    "    # Opens the file handler for the dataset file. Using variable 'f' we can access and manipulate our file anywhere in our code\n",
    "    # after the next code line.\n",
    "    f = open(filepath,\"r\")\n",
    "\n",
    "    # Predictors Collection (or your input variable) (which in this case is just the duration of eruption)\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    X3 = []\n",
    "    X4 = []\n",
    "    X5 = []\n",
    "    X6 = []\n",
    "\n",
    "    # Output Response (or your output variable) (which in this case is the duration after which next eruption will occur.)\n",
    "    Y = []\n",
    "\n",
    "    # Initializing a reader generator using reader method from csv module. A reader generator takes each line from the file\n",
    "    # and converts it into list of columns.\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # Using for loop, we are able to read one row at a time.\n",
    "    for row in reader:\n",
    "        X1.append(float(row[2]))\n",
    "        X2.append(float(row[3]))\n",
    "        X3.append(float(row[4]))\n",
    "        X4.append(float(row[5]))\n",
    "        X5.append(float(row[6]))\n",
    "        X6.append(float(row[7]))\n",
    "        Y.append(float(row[8]))\n",
    "\n",
    "    # Close the file once we have succesffuly stored all data into our X and Y variables.\n",
    "    f.close()\n",
    "\n",
    "    return [[np.array(X1),np.array(X2),np.array(X3),np.array(X4),np.array(X5),np.array(X6)],np.array(Y)]\n",
    "\n",
    "#returns[[x1,x2,x3,..,x6],y] so that X=[x1..x6],X[0]=x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = get_data(\"C:\\\\Users\\\\Edy\\\\Documents\\\\GitHub\\\\Machine-learning-Inception\\\\Week 4\\\\QnA\\\\Friday\\\\Datasets\\\\hardware.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 125.,   29.,   29.,   29.,   29.,   26.,   23.,   23.,   23.,\n",
      "         23.,  400.,  400.,   60.,   50.,  350.,  200.,  167.,  143.,\n",
      "        143.,  110.,  143.,  143.,  143.,  110.,  320.,  320.,  320.,\n",
      "        320.,  320.,  320.,   25.,   25.,   50.,   50.,   56.,   64.,\n",
      "         50.,   50.,   50.,   50.,   50.,   50.,   50.,   50.,  133.,\n",
      "        133.,  810.,  810.,  320.,  200.,  700.,  700.,  140.,  200.,\n",
      "        110.,  110.,  220.,  800.,  800.,  800.,  800.,  800.,  125.,\n",
      "         75.,   75.,   75.,   90.,  105.,  105.,  105.,   75.,   75.,\n",
      "        175.,  300.,  300.,  300.,  300.,  300.,  300.,  180.,  330.,\n",
      "        300.,  300.,  330.,  330.,  140.,  140.,  140.,  140.,  140.,\n",
      "        140.,  140.,  140.,   57.,   57.,   26.,   26.,   26.,   26.,\n",
      "        480.,  203.,  115., 1100., 1100.,  600.,  400.,  400.,  900.,\n",
      "        900.,  900.,  900.,  900.,  225.,  225.,  180.,  185.,  180.,\n",
      "        225.,   25.,   25.,   17.,   17., 1500., 1500.,  800.,   50.,\n",
      "         50.,   50.,   50.,   50.,   50.,  100.,  100.,  100.,   50.,\n",
      "         50.,   50.,  150.,  115.,  115.,   92.,   92.,   92.,   75.,\n",
      "         60.,   60.,   60.,   50.,   72.,   72.,   40.,   40.,   35.,\n",
      "         38.,   48.,   38.,   30.,  112.,   84.,   56.,   56.,   56.,\n",
      "         56.,   56.,   56.,   38.,   38.,   38.,   38.,   38.,  200.,\n",
      "        200.,  200.,  250.,  250.,  250.,  160.,  160.,  160.,  160.,\n",
      "        160.,  240.,  240.,  105.,  105.,  105.,   52.,   70.,   59.,\n",
      "         59.,   26.,   26.,   26.,  116.,   50.,   50.,   50.,   50.,\n",
      "         30.,   30.,  180.,  180.,  180.,  180.,  124.,   98.,  125.,\n",
      "        480.,  480.]), array([  256.,  8000.,  8000.,  8000.,  8000.,  8000., 16000., 16000.,\n",
      "       16000., 32000.,  1000.,   512.,  2000.,  4000.,    64.,   512.,\n",
      "         524.,   512.,  1000.,  5000.,  1500.,  3100.,  2300.,  3100.,\n",
      "         128.,   512.,   256.,   256.,   512.,   256.,  1310.,  1310.,\n",
      "        2620.,  2620.,  5240.,  5240.,   500.,  1000.,  2000.,  1000.,\n",
      "        1000.,  2000.,  2000.,  2000.,  1000.,  1000.,   512.,  1000.,\n",
      "         512.,   512.,   384.,   256.,  1000.,  1000.,  1000.,  1000.,\n",
      "        1000.,   256.,   256.,   256.,   256.,   256.,   512.,  2000.,\n",
      "        2000.,  2000.,   256.,   256.,  1000.,  2000.,  2000.,  3000.,\n",
      "         256.,   768.,   768.,   768.,   768.,   384.,   192.,   768.,\n",
      "        1000.,  1000.,  1000.,  1000.,  1000.,  2000.,  2000.,  2000.,\n",
      "        2000.,  2000.,  2000.,  2000.,  2000.,  4000.,  4000., 16000.,\n",
      "       16000.,  8000.,  8000.,    96.,  1000.,   512.,   512.,   768.,\n",
      "         768.,  2000.,  4000.,  1000.,   512.,  1000.,  1000.,  2000.,\n",
      "        2000.,  2000.,  2000.,  2000.,  2000.,  1000.,  2000.,  2000.,\n",
      "        4000.,  4000.,   768.,   768.,   768.,  2000.,  2000.,  2000.,\n",
      "        2000.,  2000.,  8000.,  1000.,  1000.,  1000.,  2000.,  2000.,\n",
      "        2000.,   512.,  2000.,  2000.,  2000.,  2000.,  2000.,  4000.,\n",
      "        4000.,  2000.,  4000.,  4000.,  4000.,  2000.,  8000.,  8000.,\n",
      "        8000., 16000.,  4000.,  8000., 16000.,  1000.,  1000.,  1000.,\n",
      "        2000.,  2000.,  4000.,  4000.,  4000.,  4000.,  4000.,  8000.,\n",
      "        8000.,  4000.,  1000.,  1000.,  2000.,   512.,   512.,  1000.,\n",
      "         512.,   512.,  1000.,  1000.,  2000.,   512.,   512.,  2000.,\n",
      "        2000.,  2000.,  4000.,  4000.,  4000.,  8000.,  8000.,  8000.,\n",
      "        8000.,  2000.,  2000.,  2000.,  2000.,  4000.,  8000.,  8000.,\n",
      "         262.,   512.,   262.,   512.,  1000.,  1000.,  2000.,   512.,\n",
      "        1000.]), array([ 6000., 32000., 32000., 32000., 16000., 32000., 32000., 32000.,\n",
      "       64000., 64000.,  3000.,  3500.,  8000., 16000.,    64., 16000.,\n",
      "        2000.,  5000.,  2000.,  5000.,  6300.,  6200.,  6200.,  6200.,\n",
      "        6000.,  2000.,  6000.,  3000.,  5000.,  5000.,  2620.,  2620.,\n",
      "       10480., 10480., 20970., 20970.,  2000.,  4000.,  8000.,  4000.,\n",
      "        8000., 16000., 16000., 16000., 12000.,  8000.,   512.,  5000.,\n",
      "        8000.,  8000.,  8000.,  2000., 16000.,  8000.,  4000., 12000.,\n",
      "        8000.,  8000.,  8000.,  8000.,  8000.,  8000.,  1000.,  8000.,\n",
      "       16000., 16000.,  1000.,  2000.,  4000.,  4000.,  8000.,  8000.,\n",
      "        2000.,  3000.,  3000., 12000.,  4500., 12000.,   768., 12000.,\n",
      "        3000.,  4000., 16000.,  2000.,  4000.,  4000.,  4000.,  4000.,\n",
      "       32000.,  8000., 32000., 32000.,  4000., 16000., 24000., 32000.,\n",
      "       32000., 32000., 16000.,   512.,  2000.,  6000.,  1500.,  2000.,\n",
      "        2000.,  4000.,  8000.,  1000.,  1000.,  4000.,  4000.,  4000.,\n",
      "        4000.,  4000.,  8000., 16000., 16000.,  4000., 12000., 12000.,\n",
      "       16000., 16000.,  1000.,  2000.,  2000.,  4000.,  8000.,  8000.,\n",
      "       16000., 16000., 16000.,  8000.,  8000.,  8000., 16000., 16000.,\n",
      "       16000.,  4000.,  8000.,  4000.,  8000.,  8000.,  8000., 16000.,\n",
      "       16000., 16000., 16000., 16000., 16000.,  8000., 16000., 32000.,\n",
      "       32000., 32000., 24000., 32000., 32000.,  1000.,  2000.,  4000.,\n",
      "        6000.,  8000.,  8000., 12000., 16000.,  8000.,  8000., 16000.,\n",
      "       24000., 16000.,  2000.,  4000.,  8000.,  4000.,  4000., 16000.,\n",
      "        4000.,  2000.,  4000.,  8000.,  8000.,  1000.,  2000.,  4000.,\n",
      "        6000.,  8000., 16000., 12000., 12000., 16000., 24000., 32000.,\n",
      "       32000.,  8000., 32000., 32000., 32000., 32000., 64000., 64000.,\n",
      "        4000.,  4000.,  4000.,  4000.,  8000.,  8000.,  8000.,  8000.,\n",
      "        4000.]), array([256.,  32.,  32.,  32.,  32.,  64.,  64.,  64.,  64., 128.,   0.,\n",
      "         4.,  65.,  65.,   0.,   0.,   8.,   0.,   0., 142.,   0.,   0.,\n",
      "         0.,   0.,   0.,   4.,   0.,   4.,   4.,   4., 131., 131.,  30.,\n",
      "        30.,  30.,  30.,   8.,   8.,   8.,   8.,   8.,   8.,   8.,   8.,\n",
      "         9.,   9.,   8.,   0.,   4.,   8.,   0.,   0.,  16.,   0.,  16.,\n",
      "        16.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,  64.,  64., 128.,\n",
      "         0.,   0.,   0.,   8.,   8.,   8.,   0.,   0.,   6.,   6.,   0.,\n",
      "         6.,   6.,   6.,   0.,   8.,   8.,   0.,   0.,   0.,   0.,   8.,\n",
      "        32.,  32.,  32.,  32.,   8.,   1.,  64.,  64.,  64.,   0.,   0.,\n",
      "         0.,   0.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,\n",
      "         8.,   0.,   8.,   8.,   8.,  16.,  16.,   2.,   8.,  16.,   8.,\n",
      "        32.,   0.,   0.,   0.,   0.,   8.,   8.,  24.,  24.,  48.,   0.,\n",
      "        24.,  24.,  12.,  24.,  24.,   0.,  16.,   2.,  32.,  32.,   4.,\n",
      "        16.,  32.,  64.,  64.,  64.,  64.,  16.,  32.,  64.,  64., 128.,\n",
      "        32.,  64., 256.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "        32.,  32.,  64., 160., 128.,   0.,   0.,  64.,   0.,   0.,   1.,\n",
      "         2.,   2.,   8.,  16.,  32.,   8.,   8.,   8.,  16.,  16.,  32.,\n",
      "         8.,  32.,  64.,  32.,  64., 128.,  32.,  24.,  48., 112., 112.,\n",
      "        96., 128.,   0.,   0.,   0.,   0.,   0.,  32.,   0.,  32.,   0.]), array([16.,  8.,  8.,  8.,  8.,  8., 16., 16., 16., 32.,  1.,  1.,  1.,\n",
      "        1.,  1.,  4.,  4.,  7.,  5.,  8.,  5.,  5.,  6.,  6.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1., 12., 12., 12., 12., 12., 12.,  1.,  1.,  1.,\n",
      "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  8.,  1.,  1.,\n",
      "        1.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  6.,  6.,  6.,  1.,  1.,\n",
      "        6.,  1.,  2.,  3.,  2.,  1.,  3.,  3.,  4.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  6., 12., 16.,  8.,  8.,  8.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  3.,  3.,  1.,  1.,  1.,\n",
      "        3.,  1.,  3.,  6.,  6.,  0.,  0.,  0.,  3.,  3.,  1.,  1.,  1.,\n",
      "        1.,  2.,  2.,  3.,  3.,  6.,  6.,  8.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  5.,  5.,  5.,  8.,  6.,  8.,  8.,  8., 16.,  8.,  8.,\n",
      "       16.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 16., 16.,  4.,  4.,\n",
      "       16.,  1.,  1.,  1.,  1.,  4.,  1.,  1.,  3.,  1.,  1.,  1.,  1.,\n",
      "        1.,  3.,  6.,  4.,  4.,  6.,  6., 12.,  8., 12., 24.,  5.,  6.,\n",
      "       26., 52., 52., 12., 12.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  0.,\n",
      "        0.]), array([128.,  32.,  32.,  32.,  16.,  32.,  32.,  32.,  32.,  64.,   2.,\n",
      "         6.,   8.,   8.,   4.,  32.,  15.,  32.,  16.,  64.,  32.,  20.,\n",
      "        64.,  64.,  12.,   3.,   6.,   3.,   5.,   6.,  24.,  24.,  24.,\n",
      "        24.,  24.,  24.,   4.,   5.,   5.,   5.,   5.,   5.,   6.,   6.,\n",
      "        12.,  12.,   1.,   1.,   5.,   8.,   1.,   1.,   3.,   2.,   2.,\n",
      "         2.,   2.,   4.,   4.,   4.,   4.,   4.,  20.,  38.,  38.,  38.,\n",
      "        10.,  10.,  24.,  19.,  24.,  48.,  24.,  24.,  24.,  24.,  24.,\n",
      "        24.,  24.,  31.,   4.,  64., 112.,   2.,   6.,   6.,   8.,  20.,\n",
      "        20.,  54.,  54.,  54.,  20.,  12.,  16.,  24.,  24.,  24.,  16.,\n",
      "         1.,   5.,   6.,   1.,   1.,   1.,   1.,   1.,   2.,   2.,   2.,\n",
      "         2.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   4.,   5.,  12.,\n",
      "        12.,   0.,   0.,   0.,   6.,   6.,   6.,   6.,   6.,  10.,   6.,\n",
      "         6.,   6.,  16.,  16.,  16., 128.,   3.,   5.,   6.,   6.,   6.,\n",
      "         6.,   6.,   8.,   8.,  10.,  16.,   8.,  16.,  24.,  24.,  32.,\n",
      "        24.,  24.,  24.,   4.,   6.,   6.,   8.,   8.,   8.,   8.,   8.,\n",
      "        32.,  32.,   8.,   8.,  32.,   2.,   4.,   5.,   7.,   7.,   8.,\n",
      "         5.,   8.,  14.,  14.,  13.,   3.,   5.,   8.,  16.,  14.,  12.,\n",
      "         8.,  12.,  24.,  16.,  16.,  32.,  28.,  26.,  52., 104., 104.,\n",
      "       176., 176.,   3.,   3.,   3.,   3.,   8.,   8.,  14.,   0.,   0.])]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## RSS Calculation ##\n",
    "#####################\n",
    "\n",
    "def RSS(x, y, betas):\n",
    "    rss = 0 #initialize rss as 0\n",
    "    for i in range(x[0].shape[0]):\n",
    "        predicted_value = (betas[0] + (betas[1] * x[0][i]) + (betas[2] * x[1][i]) + (betas[3] * x[2][i]) + (betas[4] * x[3][i]) + (betas[5] * x[4][i]) + (betas[6] * x[5][i]))\n",
    "        actual_value = y[i]\n",
    "        rss = rss + ((predicted_value - actual_value)**2) #Simultaneous update of rss    \n",
    "    return (np.sqrt(rss/x[0].shape[0]))\n",
    "\n",
    "\n",
    "def predicted_value_for_ithRow(X,i,betas):\n",
    "    return (betas[0] + (betas[1]*X[0][i]) + (betas[2]*X[1][i]) + (betas[3]*X[2][i]) + (betas[4]*X[3][i]) \n",
    "            + (betas[5]*X[4][i]) + (betas[6]*X[5][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentAlgorithm(x,y,learning_rate):\n",
    "    \n",
    "    print (\"Training Linear Regression Model using Gradient Descent\")\n",
    "    \n",
    "    maximum_iterations = 5000\n",
    "    \n",
    "    # This flag lets the program know wether the gradient descent algorithm has reached it's converged state which means wether \n",
    "    # the algorithm was able to find the local minima (where the slope of RSS wrt your parameters beta_0 and beta_1 is zero)\n",
    "    converge_status = False\n",
    "    \n",
    "    # num_rows stores the number of datapoints in the current dataset provided for training.\n",
    "    num_rows = x[0].shape[0] #shape[a,b] where a - rows, b - columns\n",
    "\n",
    "    # Initial Value of parameters ((beta_0, beta_1) - for our simple linear regression case)\n",
    "    betas = [0,0,0,0,0,0,0] #zero is initialized for beta1..beta6\n",
    "\n",
    "    # Initial Error or RSS(beta_0,beta_1) based on the initial parameter values\n",
    "    error = RSS(x,y,betas)\n",
    "    \n",
    "    print('Initial Value of RSS (Cost Function)=', error);\n",
    "    \n",
    "    # Iterate Loop\n",
    "    num_iter = 0\n",
    "    while not converge_status:\n",
    "        # for each training sample, compute the gradient (d/d_beta j(beta))\n",
    "        \n",
    "        #Below 3 are the Actual formula but we replaced this big formula as (predicted_value_for_ithRow(x,i,betas) in function\n",
    "        \n",
    "        #gradient_0 = 1/num_rows * sum([(beta_0 + beta_1*np.asarray([x1[i]])+ beta_2*np.asarray([x2[i]])+ beta_3*np.asarray([x3[i]])+ beta_4*np.asarray([x4[i]])+ beta_5*np.asarray([x5[i]])+ beta_6*np.asarray([x6[i]]) - y[i]) for i in range(num_rows)])\n",
    "        \n",
    "        #gradient_1 = 1/num_rows * sum([(beta_0 + beta_1*np.asarray([x1[i]])+ beta_2*np.asarray([x2[i]])+ beta_3*np.asarray([x3[i]])+ beta_4*np.asarray([x4[i]])+ beta_5*np.asarray([x5[i]])+ beta_6*np.asarray([x6[i]]) - y[i])*np.asarray([x1[i]]) for i in range(num_rows)])\n",
    "        \n",
    "        #gradient_2 = 1/num_rows * sum([(beta_0 + beta_1*np.asarray([x1[i]])+ beta_2*np.asarray([x2[i]])+ beta_3*np.asarray([x3[i]])+ beta_4*np.asarray([x4[i]])+ beta_5*np.asarray([x5[i]])+ beta_6*np.asarray([x6[i]]) - y[i])*np.asarray([x2[i]]) for i in range(num_rows)])\n",
    "        \n",
    "        # for each training sample, compute the gradient (d/d_beta j(beta))\n",
    "        gradient_0 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i]) for i in range(num_rows)]) \n",
    "        gradient_1 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[0][i] for i in range(num_rows)])\n",
    "        gradient_2 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[1][i] for i in range(num_rows)])\n",
    "        gradient_3 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[2][i] for i in range(num_rows)])\n",
    "        gradient_4 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[3][i] for i in range(num_rows)])\n",
    "        gradient_5 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[4][i] for i in range(num_rows)])\n",
    "        gradient_6 = 1.0/num_rows * sum([(predicted_value_for_ithRow(x,i,betas) - y[i])*x[5][i] for i in range(num_rows)])\n",
    "\n",
    "        # Computation of new parameters according to the current gradient.\n",
    "        #temp0 = beta_0 - learning_rate * gradient_0\n",
    "        temp0 = betas[0] - learning_rate * gradient_0\n",
    "        temp1 = betas[1] - learning_rate * gradient_1\n",
    "        temp2 = betas[2] - learning_rate * gradient_2\n",
    "        temp3 = betas[3] - learning_rate * gradient_3\n",
    "        temp4 = betas[4] - learning_rate * gradient_4\n",
    "        temp5 = betas[5] - learning_rate * gradient_5\n",
    "        temp6 = betas[6] - learning_rate * gradient_6\n",
    "    \n",
    "        # Simultaneous Update of Parameters Beta_0 and Beta_1.\n",
    "        #beta_0 = temp0\n",
    "        betas[0] = temp0\n",
    "        betas[1] = temp1\n",
    "        betas[2] = temp2\n",
    "        betas[3] = temp3\n",
    "        betas[4] = temp4\n",
    "        betas[5] = temp5\n",
    "        betas[6] = temp6\n",
    "\n",
    "        \n",
    "        current_error = RSS(x, y, betas)\n",
    "        \n",
    "        if num_iter % 250 == 0:\n",
    "            print ('Iteration',num_iter+1,'Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 = ', current_error)\n",
    "            \n",
    "        error = current_error   # update error \n",
    "        num_iter = num_iter + 1  # update iter\n",
    "    \n",
    "        if num_iter == maximum_iterations:\n",
    "            print (\"Training Interrupted as Maximum number of iterations were crossed.\\n\\n\")\n",
    "            converge_status = True\n",
    "\n",
    "    return (betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to predict response variable Y for new values of X using the estimated coefficientsself.\n",
    "# This method can predict Response variable (Y) for single as well as multiple values of X. If only a single numerical Value\n",
    "# input variable (X). It will return the prediction for only that single numerical\n",
    "# value. If a collection of different values for input variable (list) is passed, it will return a list of predictions\n",
    "# for each input value.\n",
    "# \"if\" statement on line number 72 takes care of understanding if the input value is singular or a list.\n",
    "def predict(coef,X):\n",
    "    beta_0 = coef[0]\n",
    "    beta_1 = coef[1]\n",
    "    beta_2 = coef[2]\n",
    "    beta_3 = coef[3]\n",
    "    beta_4 = coef[4]\n",
    "    beta_5 = coef[5]\n",
    "    beta_6 = coef[6]\n",
    "\n",
    "    fy = []\n",
    "    if len(X) > 1:\n",
    "        for x in X:\n",
    "            fy.append(beta_0 + (beta_1 * x[0])+ (beta_2 * x[1])+ (beta_3 * x[2])+ (beta_4 * x[3])+ (beta_5 * x[4])+ (beta_6 * x[5]))\n",
    "        return fy\n",
    "\n",
    "    # Our Regression Model defined using the coefficients from slr function\n",
    "    x = X[0] #declaring x to take values of x1..x6\n",
    "    Y = beta_0 + (beta_1 * x[0])+ (beta_2 * x[1])+ (beta_3 * x[2])+ (beta_4 * x[3])+ (beta_5 * x[4])+ (beta_6 * x[5])\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression Model using Gradient Descent\n",
      "Initial Value of RSS (Cost Function)= 192.09052640598452\n",
      "Iteration 1 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  169.41029982430985\n",
      "Iteration 251 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  78.01563834478966\n",
      "Iteration 501 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  77.06393837529966\n",
      "Iteration 751 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.83477398925366\n",
      "Iteration 1001 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.76841426100825\n",
      "Iteration 1251 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.73874131931434\n",
      "Iteration 1501 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.71757434148452\n",
      "Iteration 1751 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.698622274766\n",
      "Iteration 2001 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.68047520150421\n",
      "Iteration 2251 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.66281120363192\n",
      "Iteration 2501 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.64555099370251\n",
      "Iteration 2751 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.62866953379144\n",
      "Iteration 3001 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.61215405502759\n",
      "Iteration 3251 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.5959946990877\n",
      "Iteration 3501 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.58018242870567\n",
      "Iteration 3751 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.5647085579673\n",
      "Iteration 4001 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.54956464361821\n",
      "Iteration 4251 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.5347424569036\n",
      "Iteration 4501 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.52023397344084\n",
      "Iteration 4751 Current Value of RSS (Cost Function) based on updated values of beta_0 to beta_6 =  76.50603136719813\n",
      "Training Interrupted as Maximum number of iterations were crossed.\n",
      "\n",
      "\n",
      "Final Values for Beta_0 to Beta_6: [-3.888592407137899e-05, -0.0076097247388683805, 0.01387144881122186, 0.006985023012856118, 0.002442590411967058, 0.00022879871460872606, 0.0018291252805237225]\n",
      "Prediction: [31.78647611759445, 28.5268074669162]\n"
     ]
    }
   ],
   "source": [
    "#X,Y = get_data(\"../Datasets/hardware.csv\")\n",
    "# show_scatter_plot(X,Y)\n",
    "\n",
    "################################################\n",
    "## Model Training (or coefficient estimation) ##\n",
    "################################################\n",
    "# Using our gradient descent function we estimate coefficients of our regression line. The gradient descent function returns a list of \n",
    "# coefficients\n",
    "\n",
    "coefficients = gradientDescentAlgorithm(X,Y,0.0000000005)\n",
    "\n",
    "########################\n",
    "## Making Predictions ##\n",
    "########################\n",
    "\n",
    "# Using our predict function and the coefficients given by our slr function we can now predict the ERP.\n",
    "print (\"Final Values for Beta_0 to Beta_6:\",coefficients)\n",
    "print (\"Prediction:\",predict(coefficients,[[400,1000,3000,0,1,2],[400,512,3500,4,1,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy Metrics of the model\n",
      "-------------------------------------\n",
      "Residual Standard Error: 76.86082119593591\n",
      "% Residual Standard Error (over average Interval): 72.76970160793026\n",
      "\n",
      "R-Squared Value: 0.7727107121323142\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "## Performance Evaluation ##\n",
    "############################\n",
    "\n",
    "print (\"\\n\\nAccuracy Metrics of the model\\n-------------------------------------\")\n",
    "\n",
    "# Calculation of RSE\n",
    "RSS = 0\n",
    "X = np.transpose(X)\n",
    "for idx in range(0,len(X)):\n",
    "    actual_y = Y[idx]\n",
    "    predicted_y = predict(coefficients,[X[idx,0:6]])\n",
    "    RSS = RSS + ((actual_y - predicted_y)**2)\n",
    "RSE = np.sqrt((1/float(X.shape[0]-2))*RSS)\n",
    "\n",
    "\n",
    "print (\"Residual Standard Error:\",RSE)\n",
    "print (\"% Residual Standard Error (over average Interval):\", (RSE/np.mean(Y))*100)\n",
    "\n",
    "\n",
    "# Calculation of R_Squared\n",
    "TSS = 0\n",
    "for idx in range(0,len(X)):\n",
    "    actual_y = Y[idx]\n",
    "    TSS = TSS + ((actual_y - np.mean(Y))**2)\n",
    "R_Squared = ((TSS) - (RSS)) / (TSS)\n",
    "\n",
    "print (\"\\nR-Squared Value:\",R_Squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
